{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Day100_transfer_learning_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iDVwlLizgzNM","colab_type":"text"},"source":["## 作業\n","礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n","\n","\n","最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n","\n","另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"]},{"cell_type":"code","metadata":{"id":"2e1STvBO6okd","colab_type":"code","colab":{}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten\n","from keras.regularizers import l2\n","from keras import backend as K\n","from keras.models import Model\n","\n","\n","### resnet_builder.py\n","def resnet_layer(inputs,\n","        num_filters=16,\n","        kernel_size=3,\n","        strides=1,\n","        activation='relu',\n","        batch_normalization=True,\n","        conv_first=True):\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n","    # Arguments\n","        inputs (tensor): input tensor from input image or previous layer\n","        num_filters (int): Conv2D number of filters\n","        kernel_size (int): Conv2D square kernel dimensions\n","        strides (int): Conv2D square stride dimensions\n","        activation (string): activation name\n","        batch_normalization (bool): whether to include batch normalization\n","        conv_first (bool): conv-bn-activation (True) or\n","            bn-activation-conv (False)\n","    # Returns\n","        x (tensor): tensor as input to the next layer\n","    \"\"\"\n","    conv = Conv2D(num_filters,\n","            kernel_size=kernel_size,\n","            strides=strides,\n","            padding='same',\n","            kernel_initializer='he_normal',\n","            kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","def resnet(input_shape, depth=29, num_classes=10):\n","    \"\"\"ResNet Version 2 Model builder [b]\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n","    bottleneck layer\n","    First shortcut connection per layer is 1 x 1 Conv2D.\n","    Second and onwards shortcut connection is identity.\n","    At the beginning of each stage, the feature map size is halved (downsampled)\n","    by a convolutional layer with strides=2, while the number of filter maps is\n","    doubled. Within each stage, the layers have the same number filters and the\n","    same filter map sizes.\n","    Features maps sizes:\n","    conv1  : 32x32,  16\n","    stage 0: 32x32,  64\n","    stage 1: 16x16, 128\n","    stage 2:  8x8,  256\n","    # Arguments\n","        input_shape (tensor): shape of input image tensor\n","        depth (int): number of core convolutional layers\n","        num_classes (int): number of classes (CIFAR10 has 10)\n","    # Returns\n","        model (Model): Keras model instance\n","    \"\"\"\n","    if (depth - 2) % 9 != 0:\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n","    # Start model definition.\n","    num_filters_in = 16\n","    num_res_blocks = int((depth - 2) / 9)\n","\n","    inputs = Input(shape=input_shape)\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n","    x = resnet_layer(inputs=inputs,\n","                     num_filters=num_filters_in,\n","                     conv_first=True)\n","\n","    # Instantiate the stack of residual units\n","    for stage in range(3):\n","        for res_block in range(num_res_blocks):\n","            activation = 'relu'\n","            batch_normalization = True\n","            strides = 1\n","            if stage == 0:\n","                num_filters_out = num_filters_in * 4\n","                if res_block == 0:  # first layer and first stage\n","                    activation = None\n","                    batch_normalization = False\n","            else:\n","                num_filters_out = num_filters_in * 2\n","                if res_block == 0:  # first layer but not first stage\n","                    strides = 2    # downsample\n","\n","            # bottleneck residual unit\n","            y = resnet_layer(inputs=x,\n","                             num_filters=num_filters_in,\n","                             kernel_size=1,\n","                             strides=strides,\n","                             activation=activation,\n","                             batch_normalization=batch_normalization,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_in,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_out,\n","                             kernel_size=1,\n","                             conv_first=False)\n","            if res_block == 0:\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters_out,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","            x = keras.layers.add([x, y])\n","\n","        num_filters_in = num_filters_out\n","\n","    # Add classifier on top.\n","    # v2 has BN-ReLU before Pooling\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,\n","                    activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDXjz_ChU6Un","colab_type":"code","outputId":"391bbbfb-f045-4014-e351-6d5cf14fbf0d","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1565409579844,"user_tz":-480,"elapsed":3568,"user":{"displayName":"陳冠樺Joi Chen","photoUrl":"","userId":"08996694790925091938"}}},"source":["# 讀取資料集並作前處理\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vjFaWdwpU6Uv","colab_type":"code","outputId":"ad70e8e1-20e9-4e4b-846c-7822cf5e7389","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1565409582048,"user_tz":-480,"elapsed":5755,"user":{"displayName":"陳冠樺Joi Chen","photoUrl":"","userId":"08996694790925091938"}}},"source":["# 建立 ResNet 模型\n","model = resnet(input_shape=(32,32,3)) \n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 32, 32, 16)   272         activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 32, 32, 64)   1088        activation_29[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 32, 32, 64)   1088        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 32, 32, 64)   0           conv2d_36[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 32, 32, 16)   1040        activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 32, 32, 16)   2320        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 32, 32, 64)   1088        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     \n","                                                                 conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         add_11[0][0]                     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 32, 32, 16)   1040        activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 32, 32, 16)   2320        activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 32, 32, 64)   1088        activation_37[0][0]              \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 32, 32, 64)   0           add_11[0][0]                     \n","                                                                 conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         add_12[0][0]                     \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 32, 32, 64)   0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 16, 16, 64)   4160        activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 16, 16, 64)   36928       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 16, 16, 64)   256         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 16, 16, 64)   0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 16, 16, 128)  8320        add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 16, 16, 128)  8320        activation_40[0][0]              \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_46[0][0]                  \n","                                                                 conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 16, 16, 64)   8256        activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 16, 16, 64)   36928       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 16, 16, 64)   0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 16, 16, 128)  8320        activation_43[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     \n","                                                                 conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 16, 16, 64)   8256        activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 16, 16, 64)   36928       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 16, 16, 64)   256         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 16, 16, 64)   0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 16, 16, 128)  8320        activation_46[0][0]              \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 16, 16, 128)  0           add_14[0][0]                     \n","                                                                 conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 8, 8, 128)    16512       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 8, 8, 128)    0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_48[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 8, 8, 256)    33024       add_15[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 8, 8, 256)    0           conv2d_56[0][0]                  \n","                                                                 conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 8, 8, 256)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 8, 8, 128)    32896       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 8, 8, 128)    147584      activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 8, 8, 256)    33024       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n","                                                                 conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 8, 8, 128)    32896       activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 8, 8, 128)    147584      activation_54[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 8, 8, 256)    33024       activation_55[0][0]              \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     \n","                                                                 conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 8, 8, 256)    0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           activation_56[0][0]              \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n","==================================================================================================\n","Total params: 849,002\n","Trainable params: 843,786\n","Non-trainable params: 5,216\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NjJe_7JfU6Ux","colab_type":"code","outputId":"23a3e494-0fc1-44a7-b3af-372ff7495f62","colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"status":"ok","timestamp":1565412920301,"user_tz":-480,"elapsed":351376,"user":{"displayName":"陳冠樺Joi Chen","photoUrl":"","userId":"08996694790925091938"}}},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練整個資料集共 10 個循環\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","           batch_size=batch_size,\n","           epochs=epochs,\n","           verbose=1,\n","           validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 41s 817us/step - loss: 0.4559 - acc: 0.9538 - val_loss: 1.7102 - val_acc: 0.6987\n","Epoch 2/10\n","50000/50000 [==============================] - 33s 665us/step - loss: 0.4383 - acc: 0.9603 - val_loss: 1.6197 - val_acc: 0.7110\n","Epoch 3/10\n","50000/50000 [==============================] - 33s 667us/step - loss: 0.4485 - acc: 0.9559 - val_loss: 1.6872 - val_acc: 0.6980\n","Epoch 4/10\n","50000/50000 [==============================] - 33s 668us/step - loss: 0.4409 - acc: 0.9582 - val_loss: 1.4455 - val_acc: 0.7387\n","Epoch 5/10\n","50000/50000 [==============================] - 34s 672us/step - loss: 0.4289 - acc: 0.9626 - val_loss: 1.7080 - val_acc: 0.7035\n","Epoch 6/10\n","50000/50000 [==============================] - 34s 673us/step - loss: 0.4373 - acc: 0.9588 - val_loss: 1.9977 - val_acc: 0.6942\n","Epoch 7/10\n","50000/50000 [==============================] - 34s 676us/step - loss: 0.4339 - acc: 0.9606 - val_loss: 1.6326 - val_acc: 0.7209\n","Epoch 8/10\n","50000/50000 [==============================] - 34s 675us/step - loss: 0.4201 - acc: 0.9649 - val_loss: 1.6215 - val_acc: 0.7253\n","Epoch 9/10\n","50000/50000 [==============================] - 34s 675us/step - loss: 0.4372 - acc: 0.9585 - val_loss: 1.6135 - val_acc: 0.7399\n","Epoch 10/10\n","50000/50000 [==============================] - 34s 675us/step - loss: 0.4314 - acc: 0.9601 - val_loss: 1.6413 - val_acc: 0.7224\n","Test loss: 1.641289225769043\n","Test accuracy: 0.7224\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJdirOm385Rp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}